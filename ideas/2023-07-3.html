<!DOCTYPE html>
<html lang="en">
    <head>
        <title>What does Geoffrey Hinton believe about AGI existential risk? | Eli Richmond</title>
        <meta name="keywords" content="Eli Richmond, Ai, artificial intelligence, web3, crytpo, decentralization, blog, article, projects"> 
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" href="../static/xi.png">
        <link rel="stylesheet" href="../style2.css">
        <script src="../layout.js"></script>
    </head>

    <body id="home">

    <section id="masthead">
        <div id="logo"><a href="/">Eli Richmond</a></div>
    </section>
    
    <div id="content">
        <header>
            <div class="blogparent">
                <a href="/ideas">
                    Interesting Ideas:
                </a>
            </div>
        </header>
        <section id="idea">
            <h2>
                What does Geoffrey Hinton believe about AGI existential risk?
            </h2>
            
            <p>
                Pretty interesting to see what the OGs of AI are thinking.
            </p>
            <p>
                See the original: <a href="https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence" target="_blank">An article from newstatesman.com</a>
            </p>
            <p>
                See where I found this: <a href="https://marginalrevolution.com/marginalrevolution/2023/06/what-does-geoffrey-hinton-believe-about-agi-existential-risk.html" target="_blank">An article from Tyler Cowen's Marginal Revolution blog</a>
            </p>
            
            <br><br>

            <div id="ideas-content">
                <p>I asked Hinton for the strongest argument against his own position [on AGI risk]. “Yann thinks its rubbish,” he replied. “It’s all a question of whether you think that when ChatGPT says something, it understands what it’s saying. I do.”</p>
                <p>There are, he conceded, aspects of the world ChatGPT is describing that it does not understand. But he rejected LeCun’s belief that you have to “act on” the world physically in order to understand it, which current AI models cannot do. (“That’s awfully tough on astrophysicists. They can’t act on black holes.”) Hinton thinks such reasoning quickly leads you towards what he has described as a “pre-scientific concept”: consciousness, an idea he can do without. “Understanding isn’t some kind of magic internal essence. It’s an updating of what it knows.”</p>
                <p>In that sense, he thinks ChatGPT understands just as humans do. It absorbs data and adjusts its impression of the world. But there is nothing else going on, in man or machine.</p>
                <p>“I believe in [the philosopher Ludwig] Wittgenstein’s position, which is that there is no ‘inner theatre’.” If you are asked to imagine a picnic on a sunny day, Hinton suggested, you do not see the picnic in an inner theatre inside your head; it is something conjured by your perceptual system in response to a demand for data. “There is no mental stuff as opposed to physical stuff.” There are “only nerve fibres coming in”. All we do is react to sensory input.</p>
                <p>The difference between us and current AIs, Hinton thinks, is the range of input.</p>
            </div>

            <small>
            2023-07-3
            </small>
        </section>

    </div>
    </body>
</html>