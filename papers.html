<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Papers | Eli Richmond</title>
        <!-- Our CSS&JS -->
        <link rel="icon" href="static/xi.png">
        <link href="style2.css" rel="stylesheet">

        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src="layout.js"></script>
    </head>

<body>       
            <section id="masthead">
				<div id="logo"><a href="/">Eli Richmond</a></div>
            </section>

            <h1>
                Papers
            </h1>
			<h2>
				2023
			</h2>
			<dl>
				<dt>
					<a href="https://arxiv.org/pdf/2305.16291.pdf" target="_blank">
						Voyager: An Open-Ended Embodied Agent with Large Language Models
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2206.02743.pdf" target="_blank">
						A Neural Corpus Indexer for Document Retrieval
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/1909.00109.pdf" target="_blank">
						Giving BERT a Calculator *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2302.12813.pdf" target="_blank">
						Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2304.02015.pdf" target="_blank">
						How well do Large Language Models perform in Arithmetic tasks? *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2305.04032.pdf" target="_blank">
						ToolCoder: Teach Code Generation Models to use API search tools *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2303.16434.pdf" target="_blank">
						TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2305.08848.pdf" target="_blank">
						Small Models are Valuable Plug-ins for Large Language Models *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2304.08244.pdf" target="_blank">
						API-Bank: A Benchmark for Tool-Augmented LLMs *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2304.09667.pdf" target="_blank">
						GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2303.09014.pdf" target="_blank">
						ART: Automatic multi-step reasoning and tool-use for large language models *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2205.12255.pdf" target="_blank">
						TALM: Tool Augmented Language Models *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2304.08354.pdf" target="_blank">
						Tool Learning with Foundation Models *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2302.04761.pdf" target="_blank">
						Toolformer: Language Models Can Teach Themselves to Use Tools *
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2106.09685.pdf" target="_blank">
						LoRA: Low-Rank Adaptation of Large Language Models
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2304.11062.pdf" target="_blank">
						Scaling Transformer to 1M tokens and beyond with RMT
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2303.12712.pdf" target="_blank">
						Sparks of Artificial General Intelligence: Early experiments with GPT-4
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2301.07608.pdf" target="_blank">
					(Ada) Human-Timescale Adaptation in an Open-Ended Task Space
					</a>
				</dt>
			</dl>
			<small>
				* denotes literature review for ECU research
			</small>
			<h2>
				2022
			</h2>
			<dl>
				<dt>
					<a href="https://arxiv.org/pdf/2206.11795.pdf">
					(VPT) Video PreTraining: Learning to Act by Watching Unlabeled Online Videos
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2205.01068.pdf" target="_blank">
					(OPT) Open Pre-trained Transformer Language Models
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2201.08239.pdf" target="_blank">
					(LaMDA) Language Models for Dialog Applications
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank">
					Attention Is All You Need
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2205.11487.pdf" target="_blank">
					(Imagen) Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2204.06125.pdf" target="_blank">
					(DALLE2) Hierarchical Text-Conditional Image Generation with CLIP Latents
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2205.06175.pdf" target="_blank">
					(GATO) A Generalist Agent
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2010.06002.pdf" target="_blank">
					Thinking Fast and Slow in Ai
					</a>
				</dt>
            </dl>
			<h2>
				2021
			</h2>
			<dl>
				<dt>
					<a href="https://arxiv.org/pdf/2005.07865.pdf" target="_blank">
					(Attribute2Font) Creating Fonts You Want From Attributes
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2102.12092.pdf" target="_blank">
					(DALLE) Zero-Shot Text-to-Image Generation
					</a>
				</dt>
				<dt>
					<a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank">
					(GPT3) Language Models are Few-Shot Learners
					</a>
				</dt>
				<dt>
					<a href="https://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf" target="_blank">
					(MNIST) Backpropagation Applied to Handwritten Zip Code Recognition
					</a>
				</dt>
			</dl>
           
    </body>
</html>
